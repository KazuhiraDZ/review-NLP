{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"source/glove/glove.6B.100d.txt\", 'r') as f:\n",
    "    embedding_matrix = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:19<00:00, 20402.24it/s]\n"
     ]
    }
   ],
   "source": [
    "index2word = {}\n",
    "word2index = {}\n",
    "new_embedding_matrix = []\n",
    "for idx, embed_item in enumerate(tqdm(embedding_matrix)):\n",
    "    cur_words = embed_item.strip().split(\" \")\n",
    "    word = cur_words[0]\n",
    "    weight = [float(value) for value in cur_words[1:]]\n",
    "    index2word[idx] = word\n",
    "    word2index[word] = idx\n",
    "    new_embedding_matrix.append(weight)\n",
    "with open(\"source/glove/glove.6B.100d.pkl\", 'wb') as f:\n",
    "    pickle.dump(new_embedding_matrix,f)\n",
    "with open(\"source/glove/idx2word_word2idx\", 'wb') as f:\n",
    "    pickle.dump((index2word,word2index),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10109"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pad'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word[10109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 400000\n"
     ]
    }
   ],
   "source": [
    "print(len(index2word), len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不需要扩展pad\n",
    "# index2word[400000] = 'pad'\n",
    "# word2index['pad'] = 400000\n",
    "# new_embedding_matrix = np.vstack((new_embedding_matrix,np.ones((1,100))))\n",
    "with open(\"source/glove/glove.6B.100d.pkl2\", 'wb') as f:\n",
    "    pickle.dump(np.array(new_embedding_matrix),f)\n",
    "# with open(\"source/glove/idx2word_word2idx.pkl2\", 'wb') as f:\n",
    "#     pickle.dump((index2word,word2index),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"source/glove/glove.6B.100d.pkl2\", 'rb') as f:\n",
    "    new_embedding_matrix = pickle.load(f)\n",
    "#new_embedding_matrix = np.array(new_embedding_matrix)\n",
    "with open(\"source/glove/idx2word_word2idx\", 'rb') as f:\n",
    "    index2word, word2index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "with open(\"dataset.pkl\",\"rb\") as f:\n",
    "    train_data,train_label = pickle.load(f)\n",
    "with open(\"testset.pkl\",\"rb\") as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data word length\n",
    "from collections import Counter\n",
    "def countNumOfDataset(dataset):\n",
    "    counter = Counter()\n",
    "    for item in dataset:\n",
    "        words = item.strip().split(\" \")\n",
    "        counter.update([len(words)])\n",
    "    counter_list = counter.most_common()\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for x, y in counter_list:\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "    return counter_list,x_list,y_list\n",
    "co,x_l,y_l = countNumOfDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd8a82d56d8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution\n",
    "plt.scatter(x_l,y_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据数据分布选择20个词作为截断，构建数据集合\n",
    "def convert2gloveindex(dataset,dataset_label, word2index, limit=20):\n",
    "    new_dataset = []\n",
    "    new_datalabel = []\n",
    "    for item,label in zip(dataset,dataset_label):\n",
    "        words = item.strip().split(\" \")\n",
    "        if len(words) <= 1 and words[0] == '':\n",
    "            continue\n",
    "        # find word in glove, for unk we get a default index\n",
    "        cur_indexs = [word2index.setdefault(word,201534) for word in words[:limit]]\n",
    "        if len(cur_indexs) <= limit:\n",
    "            cur_indexs = cur_indexs + [word2index['pad']]*(limit - len(cur_indexs))\n",
    "        new_dataset.append(cur_indexs)\n",
    "        new_datalabel.append(label)\n",
    "    return new_dataset, new_datalabel\n",
    "\n",
    "train_data2,train_label2 = convert2gloveindex(train_data,train_label,word2index, 20)\n",
    "#test_data2,train_label2 = convert2gloveindex(test_data,train_label,word2index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3 = np.array(train_data2)\n",
    "train_label3 = np.array(train_label2)\n",
    "# new_train_label = np.zeros((train_label3.shape[0],5))\n",
    "# for idx,item in enumerate(train_label3):\n",
    "#     new_train_label[idx][item[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(train_data3,train_label3, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_y = torch.from_numpy(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataload\n",
    "deal_dataset = TensorDataset(train_x,train_y)\n",
    "train_dataloader = DataLoader(deal_dataset,batch_size=200,shuffle=True,num_workers=2)\n",
    "deal_dataset2 = TensorDataset(test_x,test_y)\n",
    "test_dataloader = DataLoader(deal_dataset2,batch_size=100,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding_matrix = torch.Tensor(new_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(textCNN, self).__init__()\n",
    "        self.vocab_size = args['vocab_size']\n",
    "        self.vocab_dim = args['vocab_dim']\n",
    "        self.n_class = args['n_class']\n",
    "        self.max_len = args['max_len']\n",
    "        self.emb_matrix = args['emb_matrix']\n",
    "        self.window_size = args['window_size']\n",
    "        # model block\n",
    "        # _weight:默认embedding矩阵，这里是glove\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.vocab_dim, _weight=self.emb_matrix)\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(self.window_size,self.vocab_dim),\n",
    "                                  stride=1, padding=(0,0)),\n",
    "                        nn.ReLU(),\n",
    "                    )\n",
    "        self.output = nn.Linear(16*18*1,self.n_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # convert to [batch,1,word,100]\n",
    "        x = x.view(x.size(0), 1, self.max_len, 100)\n",
    "        #print(x.size())\n",
    "        x = self.conv1(x)\n",
    "        # convert to [batch,16]\n",
    "        #print(x.size())\n",
    "        x = x.view(x.size(0),-1)\n",
    "        output = self.output(x)\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['vocab_size'] = len(index2word)\n",
    "args['max_len'] = 20\n",
    "args['n_class'] = 5\n",
    "args['vocab_dim'] = 100\n",
    "args['emb_matrix'] = new_embedding_matrix\n",
    "args['window_size'] = 3\n",
    "epoch = 20\n",
    "\n",
    "model = textCNN(args).cuda()\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/624], Loss: 0.6058, score:0.7600\n",
      "Epoch [1/20], Step [200/624], Loss: 0.5281, score:0.7850\n",
      "Epoch [1/20], Step [300/624], Loss: 0.5712, score:0.7800\n",
      "Epoch [1/20], Step [400/624], Loss: 0.6318, score:0.7600\n",
      "Epoch [1/20], Step [500/624], Loss: 0.6943, score:0.7450\n",
      "Epoch [1/20], Step [600/624], Loss: 0.6493, score:0.7500\n",
      "Epoch [2/20], Step [100/624], Loss: 0.5035, score:0.7850\n",
      "Epoch [2/20], Step [200/624], Loss: 0.6079, score:0.7650\n",
      "Epoch [2/20], Step [300/624], Loss: 0.6222, score:0.7500\n",
      "Epoch [2/20], Step [400/624], Loss: 0.4722, score:0.8300\n",
      "Epoch [2/20], Step [500/624], Loss: 0.6202, score:0.7350\n",
      "Epoch [2/20], Step [600/624], Loss: 0.6163, score:0.7650\n",
      "Epoch [3/20], Step [100/624], Loss: 0.4781, score:0.7900\n",
      "Epoch [3/20], Step [200/624], Loss: 0.5127, score:0.8150\n",
      "Epoch [3/20], Step [300/624], Loss: 0.7002, score:0.6900\n",
      "Epoch [3/20], Step [400/624], Loss: 0.6359, score:0.7500\n",
      "Epoch [3/20], Step [500/624], Loss: 0.6556, score:0.7300\n",
      "Epoch [3/20], Step [600/624], Loss: 0.6850, score:0.6950\n",
      "Epoch [4/20], Step [100/624], Loss: 0.5293, score:0.7950\n",
      "Epoch [4/20], Step [200/624], Loss: 0.6133, score:0.7650\n",
      "Epoch [4/20], Step [300/624], Loss: 0.5979, score:0.7300\n",
      "Epoch [4/20], Step [400/624], Loss: 0.6226, score:0.7450\n",
      "Epoch [4/20], Step [500/624], Loss: 0.6537, score:0.7350\n",
      "Epoch [4/20], Step [600/624], Loss: 0.6318, score:0.7350\n",
      "Epoch [5/20], Step [100/624], Loss: 0.6363, score:0.7550\n",
      "Epoch [5/20], Step [200/624], Loss: 0.6349, score:0.7700\n",
      "Epoch [5/20], Step [300/624], Loss: 0.6410, score:0.7150\n",
      "Epoch [5/20], Step [400/624], Loss: 0.6410, score:0.7200\n",
      "Epoch [5/20], Step [500/624], Loss: 0.5677, score:0.7400\n",
      "Epoch [5/20], Step [600/624], Loss: 0.5810, score:0.7450\n",
      "Epoch [6/20], Step [100/624], Loss: 0.5070, score:0.7800\n",
      "Epoch [6/20], Step [200/624], Loss: 0.5064, score:0.8150\n",
      "Epoch [6/20], Step [300/624], Loss: 0.5271, score:0.7800\n",
      "Epoch [6/20], Step [400/624], Loss: 0.5837, score:0.7600\n",
      "Epoch [6/20], Step [500/624], Loss: 0.5445, score:0.7850\n",
      "Epoch [6/20], Step [600/624], Loss: 0.5624, score:0.7650\n",
      "Epoch [7/20], Step [100/624], Loss: 0.3964, score:0.8150\n",
      "Epoch [7/20], Step [200/624], Loss: 0.5291, score:0.8150\n",
      "Epoch [7/20], Step [300/624], Loss: 0.5272, score:0.8000\n",
      "Epoch [7/20], Step [400/624], Loss: 0.6078, score:0.7500\n",
      "Epoch [7/20], Step [500/624], Loss: 0.5302, score:0.7850\n",
      "Epoch [7/20], Step [600/624], Loss: 0.5208, score:0.8100\n",
      "Epoch [8/20], Step [100/624], Loss: 0.5482, score:0.8000\n",
      "Epoch [8/20], Step [200/624], Loss: 0.4478, score:0.7900\n",
      "Epoch [8/20], Step [300/624], Loss: 0.6072, score:0.7950\n",
      "Epoch [8/20], Step [400/624], Loss: 0.4787, score:0.8150\n",
      "Epoch [8/20], Step [500/624], Loss: 0.5573, score:0.7400\n",
      "Epoch [8/20], Step [600/624], Loss: 0.5350, score:0.7850\n",
      "Epoch [9/20], Step [100/624], Loss: 0.5207, score:0.8050\n",
      "Epoch [9/20], Step [200/624], Loss: 0.5358, score:0.8100\n",
      "Epoch [9/20], Step [300/624], Loss: 0.5132, score:0.7650\n",
      "Epoch [9/20], Step [400/624], Loss: 0.6202, score:0.7500\n",
      "Epoch [9/20], Step [500/624], Loss: 0.5515, score:0.8000\n",
      "Epoch [9/20], Step [600/624], Loss: 0.5814, score:0.7600\n",
      "Epoch [10/20], Step [100/624], Loss: 0.5259, score:0.7900\n",
      "Epoch [10/20], Step [200/624], Loss: 0.5804, score:0.7650\n",
      "Epoch [10/20], Step [300/624], Loss: 0.5162, score:0.7900\n",
      "Epoch [10/20], Step [400/624], Loss: 0.4997, score:0.8100\n",
      "Epoch [10/20], Step [500/624], Loss: 0.5990, score:0.7450\n",
      "Epoch [10/20], Step [600/624], Loss: 0.5824, score:0.7500\n",
      "Epoch [11/20], Step [100/624], Loss: 0.4912, score:0.7850\n",
      "Epoch [11/20], Step [200/624], Loss: 0.6008, score:0.7650\n",
      "Epoch [11/20], Step [300/624], Loss: 0.5171, score:0.7700\n",
      "Epoch [11/20], Step [400/624], Loss: 0.5803, score:0.7650\n",
      "Epoch [11/20], Step [500/624], Loss: 0.4888, score:0.8100\n",
      "Epoch [11/20], Step [600/624], Loss: 0.5571, score:0.7700\n",
      "Epoch [12/20], Step [100/624], Loss: 0.4513, score:0.7800\n",
      "Epoch [12/20], Step [200/624], Loss: 0.5437, score:0.7900\n",
      "Epoch [12/20], Step [300/624], Loss: 0.5108, score:0.7900\n",
      "Epoch [12/20], Step [400/624], Loss: 0.5909, score:0.7250\n",
      "Epoch [12/20], Step [500/624], Loss: 0.5596, score:0.7950\n",
      "Epoch [12/20], Step [600/624], Loss: 0.5767, score:0.8000\n",
      "Epoch [13/20], Step [100/624], Loss: 0.4598, score:0.8450\n",
      "Epoch [13/20], Step [200/624], Loss: 0.4782, score:0.8200\n",
      "Epoch [13/20], Step [300/624], Loss: 0.5165, score:0.8200\n",
      "Epoch [13/20], Step [400/624], Loss: 0.5831, score:0.7550\n",
      "Epoch [13/20], Step [500/624], Loss: 0.4596, score:0.8100\n",
      "Epoch [13/20], Step [600/624], Loss: 0.5163, score:0.7700\n",
      "Epoch [14/20], Step [100/624], Loss: 0.4790, score:0.7900\n",
      "Epoch [14/20], Step [200/624], Loss: 0.5399, score:0.7750\n",
      "Epoch [14/20], Step [300/624], Loss: 0.4346, score:0.8300\n",
      "Epoch [14/20], Step [400/624], Loss: 0.4815, score:0.7900\n",
      "Epoch [14/20], Step [500/624], Loss: 0.4452, score:0.8450\n",
      "Epoch [14/20], Step [600/624], Loss: 0.6533, score:0.7050\n",
      "Epoch [15/20], Step [100/624], Loss: 0.4981, score:0.7850\n",
      "Epoch [15/20], Step [200/624], Loss: 0.4524, score:0.8000\n",
      "Epoch [15/20], Step [300/624], Loss: 0.4885, score:0.8000\n",
      "Epoch [15/20], Step [400/624], Loss: 0.4431, score:0.8300\n",
      "Epoch [15/20], Step [500/624], Loss: 0.5395, score:0.7700\n",
      "Epoch [15/20], Step [600/624], Loss: 0.5489, score:0.7700\n",
      "Epoch [16/20], Step [100/624], Loss: 0.4626, score:0.8350\n",
      "Epoch [16/20], Step [200/624], Loss: 0.4952, score:0.7950\n",
      "Epoch [16/20], Step [300/624], Loss: 0.5223, score:0.8000\n",
      "Epoch [16/20], Step [400/624], Loss: 0.6155, score:0.7450\n",
      "Epoch [16/20], Step [500/624], Loss: 0.4399, score:0.8100\n",
      "Epoch [16/20], Step [600/624], Loss: 0.4963, score:0.7900\n",
      "Epoch [17/20], Step [100/624], Loss: 0.5024, score:0.7900\n",
      "Epoch [17/20], Step [200/624], Loss: 0.4912, score:0.8000\n",
      "Epoch [17/20], Step [300/624], Loss: 0.5351, score:0.7750\n",
      "Epoch [17/20], Step [400/624], Loss: 0.4537, score:0.8100\n",
      "Epoch [17/20], Step [500/624], Loss: 0.5032, score:0.7900\n",
      "Epoch [17/20], Step [600/624], Loss: 0.4615, score:0.8250\n",
      "Epoch [18/20], Step [100/624], Loss: 0.4091, score:0.8150\n",
      "Epoch [18/20], Step [200/624], Loss: 0.4579, score:0.8000\n",
      "Epoch [18/20], Step [300/624], Loss: 0.5191, score:0.7650\n",
      "Epoch [18/20], Step [400/624], Loss: 0.5361, score:0.7700\n",
      "Epoch [18/20], Step [500/624], Loss: 0.5542, score:0.7450\n",
      "Epoch [18/20], Step [600/624], Loss: 0.7006, score:0.7300\n",
      "Epoch [19/20], Step [100/624], Loss: 0.3900, score:0.8450\n",
      "Epoch [19/20], Step [200/624], Loss: 0.4698, score:0.8100\n",
      "Epoch [19/20], Step [300/624], Loss: 0.5557, score:0.7250\n",
      "Epoch [19/20], Step [400/624], Loss: 0.5025, score:0.8050\n",
      "Epoch [19/20], Step [500/624], Loss: 0.5608, score:0.7350\n",
      "Epoch [19/20], Step [600/624], Loss: 0.6280, score:0.7550\n",
      "Epoch [20/20], Step [100/624], Loss: 0.5365, score:0.7500\n",
      "Epoch [20/20], Step [200/624], Loss: 0.5557, score:0.7600\n",
      "Epoch [20/20], Step [300/624], Loss: 0.4948, score:0.7600\n",
      "Epoch [20/20], Step [400/624], Loss: 0.5345, score:0.7850\n",
      "Epoch [20/20], Step [500/624], Loss: 0.5410, score:0.7900\n",
      "Epoch [20/20], Step [600/624], Loss: 0.5997, score:0.7600\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dataloader)\n",
    "for epo in range(epoch):\n",
    "    for i, (batch_x,batch_y) in enumerate(train_dataloader):\n",
    "        batch_x = batch_x.cuda().to(device)\n",
    "        batch_y = batch_y.cuda().to(device,)\n",
    "        # forward\n",
    "        output = model(batch_x)\n",
    "        #print(output)\n",
    "        #print(output)\n",
    "        #print(batch_y.float())\n",
    "        loss = criterion(output, batch_y.long())\n",
    "        \n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1) % 100 == 0:\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct = (predicted==batch_y).sum().item()\n",
    "            score = float('%.4f' %(correct / batch_y.size(0)))\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, score:{:.4f}' \n",
    "                   .format(epo+1, epoch, i+1, total_step, loss.item(), score))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test data: 62.18%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (batch_x,batch_y) in enumerate(test_dataloader):\n",
    "        batch_x = batch_x.cuda().to(device)\n",
    "        batch_y = batch_y.cuda().to(device,)\n",
    "        # forward\n",
    "        output = model(batch_x)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the test data: {}%'.format(100 * float('%.4f' %(correct / total))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(textRNN, self).__init__()\n",
    "        self.vocab_size = args['vocab_size']\n",
    "        self.vocab_dim = args['vocab_dim']\n",
    "        self.input_size = args['input_size']\n",
    "        self.hidden_size = args['hidden_size']\n",
    "        self.num_layers = args['num_layers']\n",
    "        \n",
    "        self.emb_matrix = args['emb_matrix']\n",
    "        self.max_len = args['max_len']\n",
    "        self.n_class = args['n_class']\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.vocab_dim, _weight=self.emb_matrix)\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # [batchsize,word] -> [batchsize,word,100]\n",
    "        x = self.embedding(x)\n",
    "        # 给cell中的h和c（state）设置初始状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # 计算LSTM的正向传播\n",
    "        out, _ = self.lstm(x,(h0,c0))  # output: tensor of shape (b, seq_len, hidden_size)\n",
    "        \n",
    "        # 取得out中的最后一个cell的state作为结果\n",
    "        output = self.fc(out[:,-1,:])\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args2 = {}\n",
    "args2['vocab_size'] = len(index2word)\n",
    "args2['vocab_dim'] = 100\n",
    "args2['input_size'] = 100\n",
    "args2['hidden_size'] = 128\n",
    "args2['num_layers'] = 2\n",
    "\n",
    "args2['emb_matrix'] = new_embedding_matrix\n",
    "args2['max_len'] = 20\n",
    "args2['n_class'] = 5\n",
    "\n",
    "epoch = 20\n",
    "\n",
    "model2 = textRNN(args2).cuda()\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/624], Loss: 1.1828, score:0.5550\n",
      "Epoch [1/20], Step [200/624], Loss: 1.0103, score:0.5950\n",
      "Epoch [1/20], Step [300/624], Loss: 0.8879, score:0.6200\n",
      "Epoch [1/20], Step [400/624], Loss: 0.8669, score:0.6250\n",
      "Epoch [1/20], Step [500/624], Loss: 0.7584, score:0.6750\n",
      "Epoch [1/20], Step [600/624], Loss: 0.9178, score:0.6100\n",
      "Epoch [2/20], Step [100/624], Loss: 0.7837, score:0.6750\n",
      "Epoch [2/20], Step [200/624], Loss: 0.8016, score:0.6700\n",
      "Epoch [2/20], Step [300/624], Loss: 0.9366, score:0.5900\n",
      "Epoch [2/20], Step [400/624], Loss: 0.7226, score:0.7100\n",
      "Epoch [2/20], Step [500/624], Loss: 0.7874, score:0.6700\n",
      "Epoch [2/20], Step [600/624], Loss: 0.8552, score:0.6600\n",
      "Epoch [3/20], Step [100/624], Loss: 0.6423, score:0.7100\n",
      "Epoch [3/20], Step [200/624], Loss: 0.8199, score:0.6500\n",
      "Epoch [3/20], Step [300/624], Loss: 0.7236, score:0.7100\n",
      "Epoch [3/20], Step [400/624], Loss: 0.7242, score:0.7100\n",
      "Epoch [3/20], Step [500/624], Loss: 0.6651, score:0.7250\n",
      "Epoch [3/20], Step [600/624], Loss: 0.7286, score:0.6650\n",
      "Epoch [4/20], Step [100/624], Loss: 0.6390, score:0.7250\n",
      "Epoch [4/20], Step [200/624], Loss: 0.6446, score:0.7450\n",
      "Epoch [4/20], Step [300/624], Loss: 0.6656, score:0.7250\n",
      "Epoch [4/20], Step [400/624], Loss: 0.6227, score:0.7700\n",
      "Epoch [4/20], Step [500/624], Loss: 0.6660, score:0.7000\n",
      "Epoch [4/20], Step [600/624], Loss: 0.6712, score:0.7100\n",
      "Epoch [5/20], Step [100/624], Loss: 0.6962, score:0.7350\n",
      "Epoch [5/20], Step [200/624], Loss: 0.6771, score:0.7300\n",
      "Epoch [5/20], Step [300/624], Loss: 0.6160, score:0.7700\n",
      "Epoch [5/20], Step [400/624], Loss: 0.6239, score:0.7650\n",
      "Epoch [5/20], Step [500/624], Loss: 0.6097, score:0.7200\n",
      "Epoch [5/20], Step [600/624], Loss: 0.5880, score:0.7600\n",
      "Epoch [6/20], Step [100/624], Loss: 0.4928, score:0.8000\n",
      "Epoch [6/20], Step [200/624], Loss: 0.5592, score:0.7850\n",
      "Epoch [6/20], Step [300/624], Loss: 0.5415, score:0.7650\n",
      "Epoch [6/20], Step [400/624], Loss: 0.6421, score:0.7250\n",
      "Epoch [6/20], Step [500/624], Loss: 0.6201, score:0.7300\n",
      "Epoch [6/20], Step [600/624], Loss: 0.6473, score:0.7350\n",
      "Epoch [7/20], Step [100/624], Loss: 0.6167, score:0.7300\n",
      "Epoch [7/20], Step [200/624], Loss: 0.5397, score:0.8200\n",
      "Epoch [7/20], Step [300/624], Loss: 0.5270, score:0.8000\n",
      "Epoch [7/20], Step [400/624], Loss: 0.6306, score:0.7550\n",
      "Epoch [7/20], Step [500/624], Loss: 0.5473, score:0.7650\n",
      "Epoch [7/20], Step [600/624], Loss: 0.6290, score:0.7500\n",
      "Epoch [8/20], Step [100/624], Loss: 0.5665, score:0.7500\n",
      "Epoch [8/20], Step [200/624], Loss: 0.4852, score:0.8000\n",
      "Epoch [8/20], Step [300/624], Loss: 0.5822, score:0.7550\n",
      "Epoch [8/20], Step [400/624], Loss: 0.5057, score:0.8250\n",
      "Epoch [8/20], Step [500/624], Loss: 0.5752, score:0.7400\n",
      "Epoch [8/20], Step [600/624], Loss: 0.6232, score:0.7700\n",
      "Epoch [9/20], Step [100/624], Loss: 0.4640, score:0.7850\n",
      "Epoch [9/20], Step [200/624], Loss: 0.5878, score:0.7500\n",
      "Epoch [9/20], Step [300/624], Loss: 0.5727, score:0.7350\n",
      "Epoch [9/20], Step [400/624], Loss: 0.5399, score:0.7700\n",
      "Epoch [9/20], Step [500/624], Loss: 0.5996, score:0.7700\n",
      "Epoch [9/20], Step [600/624], Loss: 0.6024, score:0.7700\n",
      "Epoch [10/20], Step [100/624], Loss: 0.4456, score:0.8000\n",
      "Epoch [10/20], Step [200/624], Loss: 0.5877, score:0.7450\n",
      "Epoch [10/20], Step [300/624], Loss: 0.5275, score:0.7800\n",
      "Epoch [10/20], Step [400/624], Loss: 0.4176, score:0.8100\n",
      "Epoch [10/20], Step [500/624], Loss: 0.5684, score:0.7450\n",
      "Epoch [10/20], Step [600/624], Loss: 0.5194, score:0.7850\n",
      "Epoch [11/20], Step [100/624], Loss: 0.4639, score:0.8200\n",
      "Epoch [11/20], Step [200/624], Loss: 0.4745, score:0.8150\n",
      "Epoch [11/20], Step [300/624], Loss: 0.4527, score:0.8500\n",
      "Epoch [11/20], Step [400/624], Loss: 0.5692, score:0.7400\n",
      "Epoch [11/20], Step [500/624], Loss: 0.5329, score:0.7850\n",
      "Epoch [11/20], Step [600/624], Loss: 0.4714, score:0.8150\n",
      "Epoch [12/20], Step [100/624], Loss: 0.3699, score:0.8850\n",
      "Epoch [12/20], Step [200/624], Loss: 0.5164, score:0.7950\n",
      "Epoch [12/20], Step [300/624], Loss: 0.5599, score:0.7450\n",
      "Epoch [12/20], Step [400/624], Loss: 0.5515, score:0.7800\n",
      "Epoch [12/20], Step [500/624], Loss: 0.5081, score:0.8000\n",
      "Epoch [12/20], Step [600/624], Loss: 0.4851, score:0.7700\n",
      "Epoch [13/20], Step [100/624], Loss: 0.6193, score:0.7150\n",
      "Epoch [13/20], Step [200/624], Loss: 0.5645, score:0.7500\n",
      "Epoch [13/20], Step [300/624], Loss: 0.4853, score:0.8050\n",
      "Epoch [13/20], Step [400/624], Loss: 0.5070, score:0.8000\n",
      "Epoch [13/20], Step [500/624], Loss: 0.5125, score:0.7550\n",
      "Epoch [13/20], Step [600/624], Loss: 0.4897, score:0.7950\n",
      "Epoch [14/20], Step [100/624], Loss: 0.4935, score:0.8200\n",
      "Epoch [14/20], Step [200/624], Loss: 0.5144, score:0.8000\n",
      "Epoch [14/20], Step [300/624], Loss: 0.4113, score:0.8250\n",
      "Epoch [14/20], Step [400/624], Loss: 0.4261, score:0.8150\n",
      "Epoch [14/20], Step [500/624], Loss: 0.4792, score:0.8200\n",
      "Epoch [14/20], Step [600/624], Loss: 0.5775, score:0.7400\n",
      "Epoch [15/20], Step [100/624], Loss: 0.4400, score:0.8050\n",
      "Epoch [15/20], Step [200/624], Loss: 0.4588, score:0.8000\n",
      "Epoch [15/20], Step [300/624], Loss: 0.5134, score:0.7950\n",
      "Epoch [15/20], Step [400/624], Loss: 0.6350, score:0.7500\n",
      "Epoch [15/20], Step [500/624], Loss: 0.4443, score:0.8000\n",
      "Epoch [15/20], Step [600/624], Loss: 0.4351, score:0.7900\n",
      "Epoch [16/20], Step [100/624], Loss: 0.4817, score:0.7650\n",
      "Epoch [16/20], Step [200/624], Loss: 0.5919, score:0.7500\n",
      "Epoch [16/20], Step [300/624], Loss: 0.4833, score:0.7800\n",
      "Epoch [16/20], Step [400/624], Loss: 0.5040, score:0.7700\n",
      "Epoch [16/20], Step [500/624], Loss: 0.4464, score:0.8100\n",
      "Epoch [16/20], Step [600/624], Loss: 0.4718, score:0.7950\n",
      "Epoch [17/20], Step [100/624], Loss: 0.5012, score:0.7900\n",
      "Epoch [17/20], Step [200/624], Loss: 0.5969, score:0.7400\n",
      "Epoch [17/20], Step [300/624], Loss: 0.5592, score:0.7550\n",
      "Epoch [17/20], Step [400/624], Loss: 0.5017, score:0.7750\n",
      "Epoch [17/20], Step [500/624], Loss: 0.4223, score:0.8250\n",
      "Epoch [17/20], Step [600/624], Loss: 0.5350, score:0.7700\n",
      "Epoch [18/20], Step [100/624], Loss: 0.4876, score:0.7950\n",
      "Epoch [18/20], Step [200/624], Loss: 0.4478, score:0.8000\n",
      "Epoch [18/20], Step [300/624], Loss: 0.5966, score:0.7700\n",
      "Epoch [18/20], Step [400/624], Loss: 0.5041, score:0.7750\n",
      "Epoch [18/20], Step [500/624], Loss: 0.5080, score:0.8000\n",
      "Epoch [18/20], Step [600/624], Loss: 0.5317, score:0.7750\n",
      "Epoch [19/20], Step [100/624], Loss: 0.4024, score:0.8300\n",
      "Epoch [19/20], Step [200/624], Loss: 0.4316, score:0.8200\n",
      "Epoch [19/20], Step [300/624], Loss: 0.4722, score:0.7900\n",
      "Epoch [19/20], Step [400/624], Loss: 0.5335, score:0.7900\n",
      "Epoch [19/20], Step [500/624], Loss: 0.5467, score:0.7400\n",
      "Epoch [19/20], Step [600/624], Loss: 0.5007, score:0.7950\n",
      "Epoch [20/20], Step [100/624], Loss: 0.4325, score:0.8250\n",
      "Epoch [20/20], Step [200/624], Loss: 0.4247, score:0.8450\n",
      "Epoch [20/20], Step [300/624], Loss: 0.4605, score:0.8150\n",
      "Epoch [20/20], Step [400/624], Loss: 0.4658, score:0.8300\n",
      "Epoch [20/20], Step [500/624], Loss: 0.4074, score:0.8150\n",
      "Epoch [20/20], Step [600/624], Loss: 0.5730, score:0.7500\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dataloader)\n",
    "for epo in range(epoch):\n",
    "    for i, (batch_x,batch_y) in enumerate(train_dataloader):\n",
    "        batch_x = batch_x.cuda().to(device)\n",
    "        batch_y = batch_y.cuda().to(device,)\n",
    "        # forward\n",
    "        output = model2(batch_x)\n",
    "        #print(output)\n",
    "        #print(output)\n",
    "        #print(batch_y.float())\n",
    "        loss = criterion(output, batch_y.long())\n",
    "        \n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1) % 100 == 0:\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct = (predicted==batch_y).sum().item()\n",
    "            score = float('%.4f' %(correct / batch_y.size(0)))\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, score:{:.4f}' \n",
    "                   .format(epo+1, epoch, i+1, total_step, loss.item(), score))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test data: 65.19%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model2.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (batch_x,batch_y) in enumerate(test_dataloader):\n",
    "        batch_x = batch_x.cuda().to(device)\n",
    "        batch_y = batch_y.cuda().to(device,)\n",
    "        # forward\n",
    "        output = model2(batch_x)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the test data: {}%'.format(100 * float('%.4f' %(correct / total))))\n",
    "torch.save(model2.state_dict(),'modelRNN.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textRNN(\n",
       "  (embedding): Embedding(400000, 100)\n",
       "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
